{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 38135 unique words tokens.\n",
      "Using vocabulary size %d. 25000\n",
      "The least frequent word in our vocabulary is '%s' and appeared %d times. ('untangle', 1)\n"
     ]
    }
   ],
   "source": [
    "import pickle \n",
    "import itertools\n",
    "import gensim \n",
    "from nltk import word_tokenize,FreqDist\n",
    "import numpy as np \n",
    "import warnings\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "warnings.filterwarnings('ignore', '.*do not.*',)\n",
    "warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "cleaned_and_tagged_sentances = []\n",
    "with open('cleaned_sentances_updated.pkl','rb') as fp:\n",
    "    cleaned_and_tagged_sentances = pickle.load(fp) \n",
    "cleaned_and_tagged = []\n",
    "with open('cleaned_sentances_tagged.pkl','rb') as fp:\n",
    "    cleaned_and_tagged = pickle.load(fp)\n",
    "    \n",
    "    \n",
    "# Count the word frequencies\n",
    "# Tokenize the sentences into words\n",
    "tokenized_sentences = [word_tokenize(sent) for sent in cleaned_and_tagged_sentances]\n",
    "word_freq = FreqDist(itertools.chain(*tokenized_sentences))\n",
    "print(\"Found %d unique words tokens.\" % len(word_freq.items()))\n",
    " \n",
    "# Get the most common words and build index_to_word and word_to_index vectors\n",
    "\n",
    "vocab = word_freq.most_common(len(texts)-1)\n",
    "index_to_word = [x[0] for x in vocab]\n",
    "word_to_index = dict([(w,i) for i,w in enumerate(index_to_word)])\n",
    " \n",
    "  \n",
    "print(\"Using vocabulary size %d.\",  vocabulary_size)\n",
    "print(\"The least frequent word in our vocabulary is '%s' and appeared %d times.\", (vocab[-1][0], vocab[-1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 9.06 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5874889, 7467970)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "texts = [[word for word in sent.split()]\n",
    "         for sent in cleaned_and_tagged_sentances]\n",
    "\n",
    "model = gensim.models.Word2Vec(texts, size=100, window=5, min_count=1, workers=2,sg=1)\n",
    "model.train(texts, total_examples=len(texts),epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('liars', 0.7143791317939758),\n",
       " ('buterin', 0.7126019597053528),\n",
       " ('misquoting', 0.6915989518165588),\n",
       " ('sun', 0.6629992723464966),\n",
       " ('attempted', 0.661956787109375),\n",
       " ('andreas', 0.647212028503418),\n",
       " ('vlad', 0.6470088362693787),\n",
       " ('justin', 0.6434707045555115),\n",
       " ('roger', 0.6434638500213623),\n",
       " ('bitcoin.com,', 0.6376467943191528)]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('vitalik' ,topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mymodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('vitalik' ,topn=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
